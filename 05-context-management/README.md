# Context Management & RAG

## Co je nového?

**RAG (Retrieval Augmented Generation)** - AI s přístupem k vlastním datům
**Vector databases** - Semantic search v kódu
**Codebase indexing** - Chytré vyhledávání podle významu
**Prompt caching** - 90% úspora na opakovaném contextu

## Proč je to důležité?

LLM mají omezený context window:
- GPT-4: 128k tokens (~300 stran)
- Claude 3.5: 200k tokens (~500 stran)
- Velké codebase: miliony tokenů

**Řešení:** Dej AI jen relevantní části

## Ukázky

1. **semantic-code-search.js** - Vyhledávání podle významu
2. **rag-codebase.js** - RAG pro velké codebase
3. **context-optimization.js** - Optimalizace context window
